version: '3.8'

services:
  # Spark Master
  # spark-master:
  #   image: bitnami/spark:latest
  #   container_name: spark-master
  #   environment:
  #     - SPARK_MODE=master
  #     - SPARK_MASTER_HOST=spark-master
  #   ports:
  #     - "7077:7077"  # Spark Master port
  #     - "8081:8080"  # Spark UI
  #   networks:
  #     - f1_network

  # # # Spark Workers (you can scale the number of workers)
  # spark-worker:
  #   image: bitnami/spark:latest
  #   # container_name: spark-worker crea automaticamente nomi quando si usa replicas
  #   environment:
  #     # - SPARK_MODE=worker
  #     # - SPARK_MASTER=spark://spark-master:7077
  #       - SPARK_MODE=worker
  #       - SPARK_MASTER=spark://spark-master:7077
  #       - SPARK_WORKER_MEMORY=2g
  #       - SPARK_WORKER_CORES=2
  #   depends_on:
  #     - spark-master
  #   deploy:
  #     replicas: 3  # You can scale this for more workers
  #   mem_limit: 2g  # Adjust memory limit as needed
  #   cpus: 2  # Adjust CPU limit as needed
  #   networks:
  #     - f1_network
      
  # # Spark Submit job container
  # spark-submit:
  #   image: jupyter/all-spark-notebook:latest # bitnami/spark:latest
  #   # build:
  #   #   context: .
  #   #   dockerfile : Dockerfile
  #   entrypoint: >
  #     /bin/bash -c "
  #     pip install -r /opt/bitnami/python/requirements.txt &&
  #     /usr/local/spark/bin/spark-submit
  #     --master spark://spark-master:7077 \
  #     --conf spark.driver.memory=2g \
  #     --conf spark.executor.memory=2g \
  #     --conf spark.executor.instances=3 
  #     /opt/bitnami/python/spark_gathering.py"
  #   depends_on:
  #     - spark-master
  #     - spark-worker
  #   volumes:
  #     - ./data_gatherer:/opt/bitnami/python
  #   networks:
  #     - f1_network




  # mongo_data:

  #   image: mongodb/mongodb-community-server:latest
  #   container_name: mongo_data
    
  #   ports:
  #     - "27019:27017"
  #   volumes:
  #     - mongodb_data:/data/db 
  #   networks:
  #     - f1_network
  
  # spark-submit:
  #   image: jupyter/all-spark-notebook:latest
  #   entrypoint: >
  #     /bin/bash -c "
  #     pip install -r /opt/bitnami/python/requirements.txt &&
  #     /usr/local/spark/bin/spark-submit
  #     --master local[*]
  #     --conf spark.driver.memory=2g
  #     --conf spark.executor.memory=2g
  #     --conf spark.executor.instances=3
  #     /opt/bitnami/python/spark_gathering.py"
  #   depends_on:
  #     - mongo_data
  #   volumes:
  #     - ./data_gatherer:/opt/bitnami/python
  #   networks:
  #     - f1_network



  # producer:
  
  #   build: ./producer
  #   container_name: producer
  #   depends_on:
  #     - kafka
  #     - zookeeper
  #   environment:
  #     - KAFKA_BROKER=kafka:9092
  #   entrypoint: ["sh", "-c", "until nc -z kafka 9092; do echo waiting for kafka; sleep 2; done; python producer.py"]

  #   networks:
  #     - f1_network


  # consumer:
  #   build: ./consumer
  #   container_name: consumer

  #   depends_on:
  #     - kafka
  #     # - mongo_data
  #     # - producer
  #   environment:
  #     - KAFKA_BROKER=kafka:9092
  #     - MONGODB_URI=mongodb://mongo_data:27017
  #   entrypoint: ["sh", "-c", "until nc -z kafka 9092; do echo waiting for kafka; sleep 5; done; echo Kafka is up!; python consumer.py"]
  #   networks:
  #     - f1_network

  kafka:
    image: wurstmeister/kafka:latest
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    # healthcheck:
    #   test: ["CMD", "kafka-topics", "--list", "--bootstrap-server", "localhost:9092"]
    #   interval: 10s
    #   timeout: 10s
    #   retries: 5
    networks:
      - f1_network

  zookeeper:
    image: wurstmeister/zookeeper:latest
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      # ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_LISTENER_PORT: 2181
    networks:
      - f1_network



  faust_producer:
    build: 
      context: ./faust_producer
    # command: python faust_producer.py worker

    environment:
      - KAFKA_BROKER=kafka://kafka:9092
    depends_on:
      - kafka
      # kafka:
      #   condition: service_healthy
    command: /bin/sh -c "sleep 30 && faust -A faust_producer worker --web-port 6066"
    volumes:
    - ./faust_producer:/app
    networks:
      - f1_network
        
  faust_app:
    build:
      context: ./faust_app
      # dockerfile: faust_app/Dockerfile
    depends_on:
    #   kafka:
    #     condition: service_healthy
      - faust_producer
    environment:
      - KAFKA_BROKER=kafka://kafka:9092
    ports:
      - "6066:6066"
    command: /bin/sh -c "sleep 30 && faust -A main worker --web-port 6066"
    # command: python main.py worker
    volumes:
    - ./faust_app:/app
    networks:
      - f1_network

  # sanic_app:
  #   build:
  #     context: ./sanic_app
  #   container_name: sanic_app
  #   ports:
  #     - "8000:8000"
  #   # depends_on:
  #   #   - mongodb
  #   environment:
  #     - MONGO_URI=mongodb://mongo_data:27017  
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://sanic_app:8000/health"]
  #     interval: 30s           
  #     timeout: 10s            
  #     retries: 3              
  #     start_period: 10s       
  #   networks:
  #     - f1_network
    
  # grafana:
  #   image: grafana/grafana:latest
  #   container_name: grafana_dashboard
  #   environment:
  #     - GF_INSTALL_PLUGINS=yesoreyeram-infinity-datasource
  #   ports:
  #     - "3001:3000"
  #   # depends_on:
  #     # - sanic_app
      
  #   networks:
  #     - f1_network

# volumes:
#   mongodb_data:
#     driver: local

networks:
  f1_network:
    driver: bridge
